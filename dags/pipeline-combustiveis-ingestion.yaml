apiVersion: v1
kind: Pod
metadata:
  name: "combustiveis-ingestion"
spec:
  hadoopConf:
    "fs.gs.auth.service.account.enable": "true"
    "fs.gs.auth.service.account.json.keyfile": "/mnt/secrets/key.json"
    "fs.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
    "fs.AbstractFileSystem.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS"
  containers:
  - name: python-container
    image: maylatt/spark-operator:3.1.1
    imagePullPolicy: Always
    securityContext:
      allowPrivilegeEscalation: false
      runAsUser: 0
    resources:
      requests:
        memory: "3Gi"
        cpu: "500m"
      limits:
        memory: "4Gi"
        cpu: "1000m"
    command: ["bash", "-c", "python3 -u /src/app/ingestion_job.py"]
    volumeMounts:
    - name: credentials
      mountPath: "/mnt/secrets"
      readOnly: true
    env:
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: "/mnt/secrets/key.json"
  volumes:
  - name: credentials
    secret:
      secretName: gcp-credentials
      optional: false 
